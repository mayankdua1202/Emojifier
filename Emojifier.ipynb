{"cells":[{"cell_type":"markdown","source":["#**Emojifier!**"],"metadata":{"id":"fCeXqcxqKOte"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","path_to_project = '/content/drive/MyDrive/PROJECTS/Emojifier/'\n","import sys    \n","sys.path.append(path_to_project)"],"metadata":{"id":"fl_d5jBo5JgN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657100952699,"user_tz":-330,"elapsed":23903,"user":{"displayName":"Mayank Dua","userId":"05393187754247664804"}},"outputId":"b471762a-7e30-4c48-d1be-519402d2b671"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["pip install emoji"],"metadata":{"id":"1tvfct1I61a8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657100974244,"user_tz":-330,"elapsed":5800,"user":{"displayName":"Mayank Dua","userId":"05393187754247664804"}},"outputId":"710a970d-47b9-4813-9ecc-ab6906b2f0b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting emoji\n","  Downloading emoji-1.7.0.tar.gz (175 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 175 kB 8.7 MB/s \n","\u001b[?25hBuilding wheels for collected packages: emoji\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=04f38c9f3523c7214f4aa769fa640b254dc5734671a5955827279f9d675f93d2\n","  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n","Successfully built emoji\n","Installing collected packages: emoji\n","Successfully installed emoji-1.7.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lMZ9xg8MFHZU"},"outputs":[],"source":["# Importing required modules\n","\n","import numpy as np\n","from emojifier_utilities import *\n","import emoji\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"Av0PwZYscFIh"},"source":["## 1 - Emojifier using Word Embeddings\n","\n","Training dataset (X, Y) where:\n","- X contains sentences (strings).\n","- Y contains an integer label between 0 and 4 corresponding to an emoji for each sentence.\n","\n","<img src=\"https://drive.google.com/uc?id=1TFLR8I6pFuamI1epx4VK1gWSvXNSSUVU\" width=\"700px\" height = \"300px\">\n","\n","Similar to training dataset, testing dataset (X, Y) consists of sentences and their corresponding emojis."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OvuoZ8pWcFIi"},"outputs":[],"source":["# Getting training and testing dataset\n","\n","X_train, Y_train = read_csv(path_to_project + 'data/training_dataset.csv')\n","X_test, Y_test = read_csv(path_to_project + 'data/testing_dataset.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DjAuDbxrcFIi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657101079428,"user_tz":-330,"elapsed":819,"user":{"displayName":"Mayank Dua","userId":"05393187754247664804"}},"outputId":"a3da1c8a-e5dc-451d-a792-9792afaeb760"},"outputs":[{"output_type":"stream","name":"stdout","text":["10\n"]}],"source":["# Getting maximum length of training dataset sentences\n","\n","maxLen = len(max(X_train, key=len).split())\n","print(maxLen)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vE1Zd2SMcFIj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657101080982,"user_tz":-330,"elapsed":4,"user":{"displayName":"Mayank Dua","userId":"05393187754247664804"}},"outputId":"f8ba2235-1d30-422c-b592-7b195c7d6376"},"outputs":[{"output_type":"stream","name":"stdout","text":["never talk to me again üòû\n","I am proud of your achievements üòÑ\n","It is the worst day in my life üòû\n","Miss you so much ‚ù§Ô∏è\n","food is life üç¥\n"]}],"source":["# Printing top few training dataset examples \n","\n","num = 5\n","for idx in range(num):\n","    print(X_train[idx], label_to_emoji(Y_train[idx]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RhRTRwVncFIm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657101084766,"user_tz":-330,"elapsed":7,"user":{"displayName":"Mayank Dua","userId":"05393187754247664804"}},"outputId":"f2f1add3-edbc-4062-d563-9fd116be0a4c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sentence 'I love my dad' has label index 0, which is emoji ‚ù§Ô∏è\n","Label index 0 in one-hot encoding format is [1. 0. 0. 0. 0.]\n"]}],"source":["# Converting the labels for both testing and training dataset to one-hot vector representations,\n","# so that they can be provided as input to softmax layer\n","\n","Y_oh_train = convert_to_one_hot(Y_train, C = 5)\n","Y_oh_test = convert_to_one_hot(Y_test, C = 5)\n","\n","# An example of one-hot vector representation\n","\n","idx = 100\n","print(f\"Sentence '{X_train[idx]}' has label index {Y_train[idx]}, which is emoji {label_to_emoji(Y_train[idx])}\", )\n","print(f\"Label index {Y_train[idx]} in one-hot encoding format is {Y_oh_train[idx]}\")"]},{"cell_type":"markdown","metadata":{"id":"KI8mJoafcFIp"},"source":["I will be using 50-dimensional GloVe vector embeddings to convert from word to its vector representation\n","\n","- word_to_index: dictionary mapping from words to their indices in the vocabulary, currently there are 400,001 words, in the vocabulary\n","\n","- index_to_word: dictionary mapping from indices to their corresponding words in the vocabulary\n","\n","- word_to_vec_map: dictionary mapping words to their GloVe vector representation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QXI3avt7cFIq"},"outputs":[],"source":["word_to_index, index_to_word, word_to_vec_map = read_glove_vecs(path_to_project + 'data/glove.6B.50d.txt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1657101109091,"user":{"displayName":"Mayank Dua","userId":"05393187754247664804"},"user_tz":-330},"id":"RB2ZN6ajcFIr","outputId":"e47146a3-21c2-4c3a-9f9e-90a76250a3b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["The index of  cucumber in the vocabulary is :  113317\n","The 289846 th word in the vocabulary is  potatos\n"]}],"source":["word = \"cucumber\"\n","idx = 289846\n","print(\"The index of \", word, \"in the vocabulary is : \", word_to_index[word])\n","print(\"The\", str(idx) + \" th word in the vocabulary is \", index_to_word[idx])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"buYjsIBecFIs"},"outputs":[],"source":["def sentence_to_avg(sentence, word_to_vec_map):\n","    \"\"\"\n","    Converts a sentence (string) into a list of words (strings). Extracts the GloVe representation of each word\n","    and averages its value into a single vector encoding the meaning of the sentence.\n","    \"\"\"\n","\n","    any_word = list(word_to_vec_map.keys())[0]\n","    avg = word_to_vec_map[any_word].shape\n","    avg = np.zeros((avg))\n","    \n","    words = sentence.lower().split()\n","    count = 0\n","    \n","    for w in words:\n","        if w in list(word_to_vec_map.keys()):\n","            avg += word_to_vec_map[w]\n","            count = count + 1\n","          \n","    if count > 0:\n","        avg = avg / count\n","    \n","    return avg"]},{"cell_type":"markdown","metadata":{"id":"NPPv5gmucFIv"},"source":["<a name='1-1'></a>\n","### 1.1 - Implementing the Model i.e. Training Phase\n","\n","Steps followed: \n","* Pass the sentence average through forward propagation\n","* Compute the cost\n","* Backpropagate to update the parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O_BzrO-TcFIv"},"outputs":[],"source":["def model(X, Y, word_to_vec_map, learning_rate = 0.01, num_iterations = 400):\n","    \"\"\"\n","    Model to train emojifier using word vector representations.\n","    \"\"\"\n","    \n","    any_word = list(word_to_vec_map.keys())[0]\n","        \n","    cost = 0\n","    \n","    m = Y.shape[0]                             # number of training examples\n","    n_y = len(np.unique(Y))                    # number of classes  \n","    n_h = word_to_vec_map[any_word].shape[0]   # dimensions of the GloVe vectors \n","    \n","    W = np.random.randn(n_y, n_h) / np.sqrt(n_h)\n","    b = np.zeros((n_y,))\n","    \n","    Y_oh = convert_to_one_hot(Y, C = n_y)\n","    \n","    for t in range(num_iterations): # Loop over the number of iterations\n","        for i in range(m):          # Loop over the training examples\n","            \n","            avg = sentence_to_avg(X[i], word_to_vec_map)\n","\n","            z = np.dot(W, avg) + b\n","            a = softmax(z)\n","\n","            cost = -1 * np.sum(Y_oh[i] * np.log(a))\n","            \n","            # Computing the gradients \n","            dz = a - Y_oh[i]\n","            dW = np.dot(dz.reshape(n_y,1), avg.reshape(1, n_h))\n","            db = dz\n","\n","            # Update parameters with Stochastic Gradient Descent\n","            W = W - learning_rate * dW\n","            b = b - learning_rate * db\n","        \n","        if t % 100 == 0:\n","            print(\"Epoch: \" + str(t) + \" --- cost = \" + str(cost))\n","            pred = predict(X, Y, W, b, word_to_vec_map)             # predict is defined in emo_utils.py\n","                                                                    # it is used to calculate the accuracy of the model and return the predictions\n","                                                                    \n","\n","    return pred, W, b   # pred - vector of predictions, numpy-array of shape (m, 1)\n","                        # W - weight matrix of the softmax layer, of shape (n_y, n_h)\n","                        # b - bias of the softmax layer, of shape (n_y,)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2478195,"status":"ok","timestamp":1657103595569,"user":{"displayName":"Mayank Dua","userId":"05393187754247664804"},"user_tz":-330},"id":"umWTqRcpcFIw","outputId":"6bf75295-2284-4af7-b4b1-d925bcaf449b","scrolled":false},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0 --- cost = 1.9520498812810076\n","Accuracy: 0.3484848484848485\n","Epoch: 100 --- cost = 0.07971818726014794\n","Accuracy: 0.9318181818181818\n","Epoch: 200 --- cost = 0.04456369243681402\n","Accuracy: 0.9545454545454546\n","Epoch: 300 --- cost = 0.03432267378786059\n","Accuracy: 0.9696969696969697\n","[[3.]\n"," [2.]\n"," [3.]\n"," [0.]\n"," [4.]\n"," [0.]\n"," [3.]\n"," [2.]\n"," [3.]\n"," [1.]\n"," [3.]\n"," [3.]\n"," [1.]\n"," [3.]\n"," [2.]\n"," [3.]\n"," [2.]\n"," [3.]\n"," [1.]\n"," [2.]\n"," [3.]\n"," [0.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [1.]\n"," [4.]\n"," [3.]\n"," [3.]\n"," [4.]\n"," [0.]\n"," [3.]\n"," [4.]\n"," [2.]\n"," [0.]\n"," [3.]\n"," [2.]\n"," [2.]\n"," [3.]\n"," [4.]\n"," [2.]\n"," [2.]\n"," [0.]\n"," [2.]\n"," [3.]\n"," [0.]\n"," [3.]\n"," [2.]\n"," [4.]\n"," [3.]\n"," [0.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [4.]\n"," [2.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [2.]\n"," [3.]\n"," [1.]\n"," [0.]\n"," [0.]\n"," [0.]\n"," [3.]\n"," [4.]\n"," [4.]\n"," [2.]\n"," [2.]\n"," [1.]\n"," [2.]\n"," [0.]\n"," [3.]\n"," [2.]\n"," [2.]\n"," [0.]\n"," [3.]\n"," [3.]\n"," [1.]\n"," [2.]\n"," [1.]\n"," [2.]\n"," [2.]\n"," [4.]\n"," [3.]\n"," [3.]\n"," [2.]\n"," [4.]\n"," [0.]\n"," [0.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [3.]\n"," [2.]\n"," [0.]\n"," [1.]\n"," [2.]\n"," [3.]\n"," [0.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [3.]\n"," [2.]\n"," [2.]\n"," [2.]\n"," [4.]\n"," [1.]\n"," [1.]\n"," [3.]\n"," [3.]\n"," [4.]\n"," [1.]\n"," [2.]\n"," [1.]\n"," [1.]\n"," [3.]\n"," [1.]\n"," [0.]\n"," [4.]\n"," [0.]\n"," [3.]\n"," [3.]\n"," [4.]\n"," [4.]\n"," [1.]\n"," [4.]\n"," [3.]\n"," [0.]\n"," [2.]]\n"]}],"source":["np.random.seed(1)\n","pred, W, b = model(X_train, Y_train, word_to_vec_map)\n","print(pred)"]},{"cell_type":"markdown","metadata":{"id":"O862gcUicFIx"},"source":["<a name='1-2'></a>\n","### 1.2 - Testing the Model i.e. Testing Phase"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1657103853784,"user":{"displayName":"Mayank Dua","userId":"05393187754247664804"},"user_tz":-330},"id":"yhb6CzhrcFIx","outputId":"66c13d17-41ec-406e-8db9-63599b930c73","scrolled":false},"outputs":[{"output_type":"stream","name":"stdout","text":["Training set:\n","Accuracy: 0.9772727272727273\n","Test set:\n","Accuracy: 0.8571428571428571\n"]}],"source":["print(\"Training set:\")\n","pred_train = predict(X_train, Y_train, W, b, word_to_vec_map)\n","print('Test set:')\n","pred_test = predict(X_test, Y_test, W, b, word_to_vec_map)"]},{"cell_type":"markdown","metadata":{"id":"WJLJRTIR4ro2"},"source":["<a name='1-3'></a>\n","### 1.3 - Try on some user provided dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1657103855839,"user":{"displayName":"Mayank Dua","userId":"05393187754247664804"},"user_tz":-330},"id":"tvCl7fUvcFIz","outputId":"cca1361e-2c6b-474c-d63d-6fb9309cb063"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.8333333333333334\n","\n","i adore you ‚ù§Ô∏è\n","i love you ‚ù§Ô∏è\n","funny lol üòÑ\n","lets play with a ball ‚öæ\n","food is ready üç¥\n","not feeling happy üòÑ\n"]}],"source":["X_my_sentences = np.array([\"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\"])\n","Y_my_labels = np.array([[0], [0], [2], [1], [4],[3]])\n","\n","pred = predict(X_my_sentences, Y_my_labels , W, b, word_to_vec_map)\n","print_predictions(X_my_sentences, pred)"]},{"cell_type":"markdown","metadata":{"id":"ZyC-BGqKcFI0"},"source":["<a name='1-4'></a>\n","### 1.4 - Confusion Matrix of Emojifier using word embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":437},"executionInfo":{"elapsed":780,"status":"ok","timestamp":1657103857663,"user":{"displayName":"Mayank Dua","userId":"05393187754247664804"},"user_tz":-330},"id":"Ab9aH9IQcFI1","outputId":"ea8ccbf1-22d5-4334-bccd-ef205797c0d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["(56,)\n","           ‚ù§Ô∏è   ‚öæ   üòÑ   üòû  üç¥\n","Predicted  0.0  1.0  2.0  3.0  4.0  All\n","Actual                                 \n","0            6    0    0    1    0    7\n","1            0    8    0    0    0    8\n","2            2    0   16    0    0   18\n","3            1    1    2   12    0   16\n","4            0    0    1    0    6    7\n","All          9    9   19   13    6   56\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 288x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["print(Y_test.shape)\n","print('           '+ label_to_emoji(0)+ '   ' + label_to_emoji(1) + '   ' +  label_to_emoji(2)+ '   ' + label_to_emoji(3)+'  ' + label_to_emoji(4))\n","print(pd.crosstab(Y_test, pred_test.reshape(56,), rownames=['Actual'], colnames=['Predicted'], margins=True))\n","plot_confusion_matrix(Y_test, pred_test)"]},{"cell_type":"markdown","metadata":{"id":"BEeTqpjlcFI2"},"source":["<a name='2'></a>\n","## 2 - Emojifier: Using LSTMs in Keras \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uZ-fy9fYcFI3"},"outputs":[],"source":["import numpy as np\n","import tensorflow\n","np.random.seed(0)\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation, Embedding\n","from tensorflow.keras.preprocessing import sequence\n","from tensorflow.keras.initializers import glorot_uniform\n","np.random.seed(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z0SixlIwcFI5"},"outputs":[],"source":["def sentences_to_indices(X, word_to_index, max_len):\n","    \"\"\"\n","    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n","    \"\"\"\n","    \n","    m = X.shape[0]      # number of training examples\n","    \n","    X_indices = np.zeros((m, max_len))\n","    \n","    for i in range(m):\n","        \n","        sentence_words = X[i].lower().split()\n","        j = 0\n","        \n","        for w in sentence_words:\n","            if w in list(word_to_index.keys()):\n","                X_indices[i, j] = word_to_index[w]\n","                j =  j+1\n","            \n","    return X_indices"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":716,"status":"ok","timestamp":1657103862171,"user":{"displayName":"Mayank Dua","userId":"05393187754247664804"},"user_tz":-330},"id":"oBL1PMOCcFI6","outputId":"36c9d402-bf68-4a6d-af46-2b98409b8c48"},"outputs":[{"output_type":"stream","name":"stdout","text":["X1 = ['funny lol' 'lets play baseball' 'food is ready for you']\n","X1_indices =\n"," [[155345. 225122.      0.      0.      0.]\n"," [220930. 286375.  69714.      0.      0.]\n"," [151204. 192973. 302254. 151349. 394475.]]\n"]}],"source":["# Just giving examples on how above function will work.\n","\n","X1 = np.array([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])\n","X1_indices = sentences_to_indices(X1, word_to_index, max_len=5)\n","print(\"X1 =\", X1)\n","print(\"X1_indices =\\n\", X1_indices)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XBlEpiVkcFI7"},"outputs":[],"source":["def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n","    \"\"\"\n","    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.\n","    \"\"\"\n","    \n","    vocab_size = len(word_to_index) + 1              # adding 1 for representing unknown word\n","    any_word = list(word_to_vec_map.keys())[0]\n","    emb_dim = word_to_vec_map[any_word].shape[0]\n","      \n","    emb_matrix = np.zeros((vocab_size, emb_dim))\n","    \n","    for word, idx in word_to_index.items():\n","        emb_matrix[idx, :] = word_to_vec_map[word]\n","\n","    embedding_layer = Embedding(vocab_size, emb_dim, trainable=False)\n","    \n","    embedding_layer.build((None,))\n","    embedding_layer.set_weights([emb_matrix])\n","    \n","    return embedding_layer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2555,"status":"ok","timestamp":1657103864722,"user":{"displayName":"Mayank Dua","userId":"05393187754247664804"},"user_tz":-330},"id":"Gn4iGb0AcFI7","outputId":"308b09d8-e9ef-45bc-8f1c-fb01a6f148e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["weights[0][1][1] = 0.39031\n","Input_dim 400001\n","Output_dim 50\n"]}],"source":["# Embedding layer set properties\n","\n","embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n","print(\"weights[0][1][1] =\", embedding_layer.get_weights()[0][1][1])\n","print(\"Input_dim\", embedding_layer.input_dim)\n","print(\"Output_dim\",embedding_layer.output_dim)"]},{"cell_type":"markdown","metadata":{"id":"jAAJirtN4ro_"},"source":["<a name='2-1'></a>\n","### 2.1 - Implementing the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pb2ugsSUcFI7"},"outputs":[],"source":["def Emojifier(input_shape, word_to_vec_map, word_to_index):\n","    \"\"\"\n","    Function creating the Emojifier model.\n","    \"\"\"\n","    \n","    sentence_indices = Input(shape=input_shape, dtype='int32')\n","    \n","    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n","    embeddings = embedding_layer(sentence_indices)   \n","    \n","    X = LSTM(units=128, return_sequences=True)(embeddings)\n","    \n","    X = Dropout(rate=0.5)(X)\n","    \n","    X = LSTM(units=128, return_sequences=False)(X)  # Here 'return_sequences' will decide, whether we want to\n","                                                    # return every hidden states or only the last one.\n","    \n","    X = Dropout(rate=0.5)(X)\n","    \n","    X = Dense(units=5)(X)\n","    \n","    X = Activation('softmax')(X)\n","    \n","    model = Model(inputs=sentence_indices, outputs=X)\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1009,"status":"ok","timestamp":1657103865727,"user":{"displayName":"Mayank Dua","userId":"05393187754247664804"},"user_tz":-330},"id":"8fLhXJ9ucFI8","outputId":"2ed01955-5bfd-4082-99c6-7005b6a7f5c9","scrolled":false},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 10)]              0         \n","                                                                 \n"," embedding_1 (Embedding)     (None, 10, 50)            20000050  \n","                                                                 \n"," lstm (LSTM)                 (None, 10, 128)           91648     \n","                                                                 \n"," dropout (Dropout)           (None, 10, 128)           0         \n","                                                                 \n"," lstm_1 (LSTM)               (None, 128)               131584    \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense (Dense)               (None, 5)                 645       \n","                                                                 \n"," activation (Activation)     (None, 5)                 0         \n","                                                                 \n","=================================================================\n","Total params: 20,223,927\n","Trainable params: 223,877\n","Non-trainable params: 20,000,050\n","_________________________________________________________________\n"]}],"source":["model = Emojifier((maxLen,), word_to_vec_map, word_to_index)\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"e4tfBbhp4rpC"},"source":["<a name='2-2'></a>\n","### 2.2 - Compiling the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aMf79f45cFI9"},"outputs":[],"source":["model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"mX6NORy7cFI9"},"source":["<a name='2-3'></a>\n","### 2.3 - Training the Model "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":39160,"status":"ok","timestamp":1657103904882,"user":{"displayName":"Mayank Dua","userId":"05393187754247664804"},"user_tz":-330},"id":"UgsBnWQqcFI-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f8f66f17-d154-44c5-cb4d-65b90d176dc0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","5/5 [==============================] - 4s 26ms/step - loss: 1.5977 - accuracy: 0.2576\n","Epoch 2/50\n","5/5 [==============================] - 0s 26ms/step - loss: 1.5067 - accuracy: 0.3485\n","Epoch 3/50\n","5/5 [==============================] - 0s 25ms/step - loss: 1.4918 - accuracy: 0.3106\n","Epoch 4/50\n","5/5 [==============================] - 0s 25ms/step - loss: 1.4001 - accuracy: 0.3788\n","Epoch 5/50\n","5/5 [==============================] - 0s 27ms/step - loss: 1.2800 - accuracy: 0.5000\n","Epoch 6/50\n","5/5 [==============================] - 0s 27ms/step - loss: 1.2160 - accuracy: 0.5227\n","Epoch 7/50\n","5/5 [==============================] - 0s 22ms/step - loss: 1.1286 - accuracy: 0.5833\n","Epoch 8/50\n","5/5 [==============================] - 0s 23ms/step - loss: 1.0100 - accuracy: 0.6061\n","Epoch 9/50\n","5/5 [==============================] - 0s 22ms/step - loss: 0.8190 - accuracy: 0.7121\n","Epoch 10/50\n","5/5 [==============================] - 0s 23ms/step - loss: 0.7777 - accuracy: 0.6970\n","Epoch 11/50\n","5/5 [==============================] - 0s 23ms/step - loss: 0.6129 - accuracy: 0.7500\n","Epoch 12/50\n","5/5 [==============================] - 0s 23ms/step - loss: 0.6256 - accuracy: 0.7500\n","Epoch 13/50\n","5/5 [==============================] - 0s 22ms/step - loss: 0.5844 - accuracy: 0.7727\n","Epoch 14/50\n","5/5 [==============================] - 0s 24ms/step - loss: 0.4949 - accuracy: 0.8485\n","Epoch 15/50\n","5/5 [==============================] - 0s 25ms/step - loss: 0.4230 - accuracy: 0.8409\n","Epoch 16/50\n","5/5 [==============================] - 0s 24ms/step - loss: 0.3890 - accuracy: 0.8409\n","Epoch 17/50\n","5/5 [==============================] - 0s 25ms/step - loss: 0.3680 - accuracy: 0.8561\n","Epoch 18/50\n","5/5 [==============================] - 0s 26ms/step - loss: 0.3113 - accuracy: 0.9091\n","Epoch 19/50\n","5/5 [==============================] - 0s 25ms/step - loss: 0.2752 - accuracy: 0.8939\n","Epoch 20/50\n","5/5 [==============================] - 0s 24ms/step - loss: 0.2671 - accuracy: 0.9015\n","Epoch 21/50\n","5/5 [==============================] - 0s 26ms/step - loss: 0.2155 - accuracy: 0.9015\n","Epoch 22/50\n","5/5 [==============================] - 0s 28ms/step - loss: 0.2113 - accuracy: 0.9242\n","Epoch 23/50\n","5/5 [==============================] - 0s 27ms/step - loss: 0.1512 - accuracy: 0.9470\n","Epoch 24/50\n","5/5 [==============================] - 0s 25ms/step - loss: 0.1322 - accuracy: 0.9621\n","Epoch 25/50\n","5/5 [==============================] - 0s 25ms/step - loss: 0.1834 - accuracy: 0.9470\n","Epoch 26/50\n","5/5 [==============================] - 0s 24ms/step - loss: 0.4801 - accuracy: 0.8636\n","Epoch 27/50\n","5/5 [==============================] - 0s 24ms/step - loss: 0.3590 - accuracy: 0.8788\n","Epoch 28/50\n","5/5 [==============================] - 0s 27ms/step - loss: 0.2875 - accuracy: 0.8712\n","Epoch 29/50\n","5/5 [==============================] - 0s 28ms/step - loss: 0.1910 - accuracy: 0.9545\n","Epoch 30/50\n","5/5 [==============================] - 0s 24ms/step - loss: 0.1954 - accuracy: 0.9394\n","Epoch 31/50\n","5/5 [==============================] - 0s 23ms/step - loss: 0.1732 - accuracy: 0.9318\n","Epoch 32/50\n","5/5 [==============================] - 0s 23ms/step - loss: 0.1072 - accuracy: 0.9773\n","Epoch 33/50\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0979 - accuracy: 0.9773\n","Epoch 34/50\n","5/5 [==============================] - 0s 23ms/step - loss: 0.1134 - accuracy: 0.9697\n","Epoch 35/50\n","5/5 [==============================] - 0s 23ms/step - loss: 0.0925 - accuracy: 0.9697\n","Epoch 36/50\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0639 - accuracy: 0.9848\n","Epoch 37/50\n","5/5 [==============================] - 0s 23ms/step - loss: 0.1402 - accuracy: 0.9697\n","Epoch 38/50\n","5/5 [==============================] - 0s 27ms/step - loss: 0.1239 - accuracy: 0.9697\n","Epoch 39/50\n","5/5 [==============================] - 0s 24ms/step - loss: 0.1894 - accuracy: 0.9318\n","Epoch 40/50\n","5/5 [==============================] - 0s 25ms/step - loss: 0.1297 - accuracy: 0.9394\n","Epoch 41/50\n","5/5 [==============================] - 0s 27ms/step - loss: 0.1273 - accuracy: 0.9470\n","Epoch 42/50\n","5/5 [==============================] - 0s 25ms/step - loss: 0.1359 - accuracy: 0.9470\n","Epoch 43/50\n","5/5 [==============================] - 0s 24ms/step - loss: 0.0560 - accuracy: 0.9773\n","Epoch 44/50\n","5/5 [==============================] - 0s 25ms/step - loss: 0.1050 - accuracy: 0.9545\n","Epoch 45/50\n","5/5 [==============================] - 0s 27ms/step - loss: 0.0386 - accuracy: 0.9924\n","Epoch 46/50\n","5/5 [==============================] - 0s 25ms/step - loss: 0.0408 - accuracy: 0.9924\n","Epoch 47/50\n","5/5 [==============================] - 0s 24ms/step - loss: 0.0257 - accuracy: 1.0000\n","Epoch 48/50\n","5/5 [==============================] - 0s 27ms/step - loss: 0.0259 - accuracy: 1.0000\n","Epoch 49/50\n","5/5 [==============================] - 0s 28ms/step - loss: 0.0117 - accuracy: 1.0000\n","Epoch 50/50\n","5/5 [==============================] - 0s 25ms/step - loss: 0.0121 - accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f47401584d0>"]},"metadata":{},"execution_count":25}],"source":["X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n","Y_train_oh = convert_to_one_hot(Y_train, C = 5)\n","model.fit(X_train_indices, Y_train_oh, epochs = 50, batch_size = 32, shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"Y7blODM64rpG"},"source":["<a name='2-4'></a>\n","### 2.4 - Evaluating the Model "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11323,"status":"ok","timestamp":1657103916193,"user":{"displayName":"Mayank Dua","userId":"05393187754247664804"},"user_tz":-330},"id":"sIbcdVibcFJA","outputId":"5c4f7233-aad1-484b-d4a3-8686344df7c6","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 1s 13ms/step - loss: 0.4752 - accuracy: 0.8750\n","\n","Test accuracy =  0.875\n"]}],"source":["X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n","Y_test_oh = convert_to_one_hot(Y_test, C = 5)\n","loss, acc = model.evaluate(X_test_indices, Y_test_oh)\n","print()\n","print(\"Test accuracy = \", acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11704,"status":"ok","timestamp":1657103927887,"user":{"displayName":"Mayank Dua","userId":"05393187754247664804"},"user_tz":-330},"id":"mjMyEGmYcFJC","outputId":"3d33822f-a3d4-4555-e6cf-04d6586ab230"},"outputs":[{"output_type":"stream","name":"stdout","text":["Expected emoji:üòû prediction: work is hard\tüòÑ\n","Expected emoji:üòû prediction: This girl is messing with me\t‚ù§Ô∏è\n","Expected emoji:üòû prediction: work is horrible\tüòÑ\n","Expected emoji:üòû prediction: she is a bully\t‚ù§Ô∏è\n","Expected emoji:üòû prediction: My life is so boring\t‚ù§Ô∏è\n","Expected emoji:üòû prediction: go away\t‚öæ\n","Expected emoji:üç¥ prediction: I did not have breakfast ‚ù§Ô∏è\n"]}],"source":["# This code will show mislabelled predictions by our model\n","\n","C = 5\n","y_test_oh = np.eye(C)[Y_test.reshape(-1)]\n","X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n","pred = model.predict(X_test_indices)\n","for i in range(len(X_test)):\n","    x = X_test_indices\n","    num = np.argmax(pred[i])\n","    if(num != Y_test[i]):\n","        print('Expected emoji:'+ label_to_emoji(Y_test[i]) + ' prediction: '+ X_test[i] + label_to_emoji(num).strip())"]},{"cell_type":"markdown","metadata":{"id":"fmJX6Mbc4rpI"},"source":["<a name='2-5'></a>\n","### 2.5 - Running Emojifier on our own input"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1657103927887,"user":{"displayName":"Mayank Dua","userId":"05393187754247664804"},"user_tz":-330},"id":"wEgCsIE7cFJE","outputId":"454bc00d-ea92-47c3-b244-6b4034563c50"},"outputs":[{"output_type":"stream","name":"stdout","text":["not feeling happy üòû\n"]}],"source":["given_sentence = 'not feeling happy'     # Change this sentence\n","\n","x_test = np.array([given_sentence])\n","X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n","print(x_test[0] +' '+  label_to_emoji(np.argmax(model.predict(X_test_indices))))"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Emojifier.ipynb","provenance":[],"toc_visible":true},"coursera":{"schema_names":["DLSC5W2-A2"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}